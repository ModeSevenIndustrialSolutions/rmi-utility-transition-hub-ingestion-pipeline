{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41652f59-1798-4431-90dc-592dd4f64a7f",
   "metadata": {},
   "source": [
    "## Load RMI Utilities Transition Hub Data (from https://utilitytransitionhub.rmi.org/data-download/ for Data Vault Prototype)\n",
    "\n",
    "Copyright (C) 2021 OS-Climate\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "### We have local copies of the released datasets rooted in the S3_BUCKET : RMI/RMI-202*\n",
    "\n",
    "### The next step is to enrich with OS-C Factor metadata\n",
    "\n",
    "Contributed by Michael Tiemann (Github: MichaelTiemannOSC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92377eb7-1d1b-4662-ac08-99877153832b",
   "metadata": {},
   "source": [
    "Load Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac18bf3b-80d7-4b25-8ae4-9273709a0789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the AWS Account page, copy the export scripts from the appropriate role using the \"Command Line or Programmatic Access\" link\n",
    "# Paste the copied text into ~/credentials.env\n",
    "\n",
    "from dotenv import dotenv_values, load_dotenv\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "dotenv_dir = os.environ.get('CREDENTIAL_DOTENV_DIR', os.environ.get('PWD', '/opt/app-root/src'))\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / 'credentials.env'\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path,override=True)\n",
    "\n",
    "import osc_ingest_trino as osc\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import json\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5877739-a3c7-4f6c-ae92-b2288f511b41",
   "metadata": {},
   "source": [
    "Create an S3 resource for the bucket holding source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355122da-ec89-4ac7-83aa-2774f18d20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3_source = boto3.resource(\n",
    "    service_name=\"s3\",\n",
    "    endpoint_url=os.environ['S3_LANDING_ENDPOINT'],\n",
    "    aws_access_key_id=os.environ['S3_LANDING_ACCESS_KEY'],\n",
    "    aws_secret_access_key=os.environ['S3_LANDING_SECRET_KEY'],\n",
    ")\n",
    "source_bucket = s3_source.Bucket(os.environ['S3_LANDING_BUCKET'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b20c75d-8cb4-445e-8f52-0691c289fa0c",
   "metadata": {},
   "source": [
    "rmi_20210929_files = {}\n",
    "for file in source_bucket.objects.filter(Prefix='RMI/RMI-20210929'):\n",
    "    if file.key.endswith('csv'):\n",
    "        rmi_20210929_files[file.key] = file.last_modified.isoformat()\n",
    "# print(rmi_20210929_files)\n",
    "\n",
    "rmi_20211120_files = {}\n",
    "for file in source_bucket.objects.filter(Prefix='RMI/RMI-20211120'):\n",
    "    if file.key.endswith('csv'):\n",
    "        rmi_20211120_files[file.key] = file.last_modified.isoformat()\n",
    "# print(rmi_20211120_files)\n",
    "\n",
    "rmi_20220119_files = {}\n",
    "for file in source_bucket.objects.filter(Prefix='RMI/RMI-20220119'):\n",
    "    if file.key.endswith('csv'):\n",
    "        rmi_20220119_files[file.key] = file.last_modified.isoformat()\n",
    "print(rmi_20220119_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c689692-e057-4123-b58b-ca15de0aeebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an S3 client.  We will user later when we write out data and metadata\n",
    "\n",
    "trino_bucket = osc.attach_s3_bucket(\"S3_DEV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2cea5bd-c682-4f16-8943-6f10d7955f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('default',), ('information_schema',), ('sandbox',)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import trino\n",
    "from sqlalchemy.engine import create_engine\n",
    "\n",
    "ingest_catalog = 'osc_datacommons_dev'\n",
    "ingest_schema = 'sandbox'\n",
    "\n",
    "sqlstring = 'trino://{user}@{host}:{port}/'.format(\n",
    "    user = os.environ['TRINO_USER'],\n",
    "    host = os.environ['TRINO_HOST'],\n",
    "    port = os.environ['TRINO_PORT']\n",
    ")\n",
    "sqlargs = {\n",
    "    'auth': trino.auth.JWTAuthentication(os.environ['TRINO_PASSWD']),\n",
    "    'http_scheme': 'https',\n",
    "    'catalog': ingest_catalog,\n",
    "    'schema': ingest_schema,\n",
    "}\n",
    "engine = create_engine(sqlstring, connect_args = sqlargs)\n",
    "connection = engine.connect()\n",
    "\n",
    "# Show available schemas to ensure trino connection is set correctly\n",
    "qres = engine.execute('show schemas')\n",
    "display(qres.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7eab8e-10be-4fa1-b9a2-05006bbaa9ac",
   "metadata": {},
   "source": [
    "Load RMI data file using pandas *read_csv* and appropriate dtype dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e092d951-37d5-429b-955c-2ace5b1f3650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Current (November 20, 2021) dataset sometimes represents YEAR as floating point number.  We will read as string and fix later.\n",
    "\n",
    "dtype_dict = {\n",
    "    # Table Name maps to dtypes (note that NaNs cannot encode to integers, so must do ex post facto fixes)\n",
    "    'assets_earnings_investments':\n",
    "        {'respondent_id':'int32',\n",
    "         'asset_value':'float64', 'earnings_value':'float64', 'investment_value':'float64'},\n",
    "    'customers_sales':\n",
    "        {'respondent_id':'int32',\n",
    "         'customers':'Int32',\n",
    "         'sales':'float64', 'revenues':'float64'},\n",
    "    'debt_equity_returns':\n",
    "        {'respondent_id':'int32',\n",
    "         'rate_base_actual':'float64', 'equity_actual':'float64', 'debt_actual':'float64', \n",
    "         'equity_ratio_actual':'float64', 'returns_actual':'float64', 'earnings_actual':'float64',\n",
    "         'interest_actual':'float64', 'fed_tax_expense_actual':'float64',\n",
    "         'pre_tax_net_income_actual':'float64', 'ROR_actual':'float64', 'ROE_actual':'float64',\n",
    "         'equity_ratio':'float64', 'ROR':'float64', 'ROE':'float64',\n",
    "         'interest_rate':'float64',\n",
    "         'effective_fed_tax_rate':'float64', 'equity_authorized':'float64', 'debt_authorized':'float64',\n",
    "         'returns_authorized':'float64', 'earnings_authorized':'float64', 'interest_authorized':'float64', \n",
    "         'interest_rate_authorized':'float64'},\n",
    "    'emissions_targets':\n",
    "        {'respondent_id':'Int32',\n",
    "         'CO2_historical':'float64', 'CO2_target':'float64', 'CO2_target_all_years':'float64', 'CO2_1point5C':'float64',\n",
    "         'generation_historical':'float64', 'generation_projected':'float64', 'generation_1point5C':'float64',\n",
    "         'CO2_intensity_historical':'float64', 'CO2_intensity_target':'float64', 'CO2_intensity_target_all_years':'float64', 'CO2_intensity_1point5C':'float64'},\n",
    "    'employees':\n",
    "        {'respondent_id':'int32',\n",
    "         'employees':'int32'},\n",
    "    'expenditure_bills_burden':\n",
    "        {'respondent_id':'int32',\n",
    "         'expenditure':'float64', 'bill':'float64', 'burden':'float64'},\n",
    "    'expenditure_bills_burden_detail': 'string',\n",
    "    'housing_units_income':\n",
    "        {'respondent_id':'int32',\n",
    "         'housing_units':'float64', 'income':'float64'},\n",
    "    'net_plant_balance':\n",
    "        {'respondent_id':'int32',\n",
    "         'original_cost':'float64', 'accum_depr':'float64', 'net_plant_balance':'float64',\n",
    "         'ARC':'float64', 'ARC_accum_depr':'float64', 'net_ARC':'float64'},\n",
    "    'operations_emissions_by_fuel':\n",
    "        {'respondent_id':'int32', 'plant_id_eia':'Int32',\n",
    "         'latitude':'float64', 'longitude':'float64',\n",
    "         'operating_month':'Int32', 'operating_year':'Int32',\n",
    "         'retirement_month':'Int32', 'retirement_year':'Int32',\n",
    "         'generation':'float64', 'fuel_consumption':'float64',\n",
    "         'emissions_c02':'float64', 'emissions_nox':'float64', 'emissions_sox':'float64'},\n",
    "    'operations_emissions_by_tech':\n",
    "        {'respondent_id':'int32', 'plant_id_eia':'Int32',\n",
    "         'latitude':'float64', 'longitude':'float64',\n",
    "         'capacity':'float64', 'year_end_capacity':'float64', 'generation':'float64', 'potential_generation':'float64',\n",
    "         'capacity_factor':'float64', 'fuel_consumption':'float64',\n",
    "         'emissions_c02':'float64', 'emissions_nox':'float64', 'emissions_sox':'float64'},\n",
    "    'revenue_by_tech':\n",
    "        {'respondent_id':'int32',\n",
    "         'revenue_total':'float64', 'revenue_residential':'float64' },\n",
    "    'state_targets': 'string',\n",
    "    'utility_information':\n",
    "        {'respondent_id':'int32', 'utility_id_eia':'Int32',\n",
    "         'duplicate_utility_id_eia':'boolean' },\n",
    "    'utility_state_map':\n",
    "        {'respondent_id':'int32',\n",
    "         'capacity_owned_in_state':'float64',\n",
    "         'capacity_operated_in_state':'float64',\n",
    "         'mwh_sales_in_state':'float64', }\n",
    "}\n",
    "\n",
    "fillna_dict = {\n",
    "    'assets_earnings_investments':\n",
    "        {'asset_value': 0, 'earnings_value': 0, 'investment_value': 0},\n",
    "    'customer_sales':\n",
    "        {'customers': 0, 'sales': 0, 'revenues': 0}\n",
    "}\n",
    "\n",
    "dropna_dict = {\n",
    "    'emissions_targets': {'respondent_id':'int32'},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdb917b-ae80-4446-8539-552791ed8036",
   "metadata": {},
   "source": [
    "Create the actual metadata for the source.  In this case, it is *rmi_utility_transition_hub*\n",
    "\n",
    "We read and interpret the data dictionary that comes with the data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6739837b-0e5d-4aa3-9794-8e2e70ab3143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "if False:\n",
    "    rmi_20210929_b = io.BytesIO(source_bucket.Object('RMI/RMI-20210929.zip').get()['Body'].read())\n",
    "    rmi_20210929_zip = zipfile.ZipFile(rmi_20210929_b, mode='r')\n",
    "    del(rmi_20210929_b)\n",
    "    # display(zipfile.ZipFile(rmi_20210929_zip, mode='r').filelist)\n",
    "    rmi_dd = rmi_20210929_zip.read('data_download/RMI Utility Transition Hub Data Dictionary.xlsx')\n",
    "\n",
    "    # Read all the sheets.  rmi_excel['sheet_name'] gives a specific sheet\n",
    "    rmi_20210929_xls = pd.read_excel(rmi_dd, sheet_name=None, dtype=str)\n",
    "\n",
    "    rmi_20211120_b = io.BytesIO(source_bucket.Object('RMI/RMI-20211120.zip').get()['Body'].read())\n",
    "    rmi_20211120_zip = zipfile.ZipFile(rmi_20211120_b, mode='r')\n",
    "    del(rmi_20211120_b)\n",
    "    # display(zipfile.ZipFile(rmi_20211120_zip, mode='r').filelist)\n",
    "    rmi_dd = rmi_20211120_zip.read('data_dictionary.xlsx')\n",
    "\n",
    "    # Read all the sheets.  rmi_excel['sheet_name'] gives a specific sheet\n",
    "    rmi_20211120_xls = pd.read_excel(rmi_dd, sheet_name=None, dtype=str)\n",
    "\n",
    "rmi_20220119_b = io.BytesIO(source_bucket.Object('RMI/RMI-20220119.zip').get()['Body'].read())\n",
    "rmi_20220119_zip = zipfile.ZipFile(rmi_20220119_b, mode='r')\n",
    "del(rmi_20220119_b)\n",
    "# display(zipfile.ZipFile(rmi_20220119_zip, mode='r').filelist)\n",
    "rmi_dd = rmi_20220119_zip.read('data_dictionary.xlsx')\n",
    "\n",
    "# Read all the sheets.  rmi_excel['sheet_name'] gives a specific sheet\n",
    "rmi_20220119_xls = pd.read_excel(rmi_dd, sheet_name=None, dtype=str)\n",
    "\n",
    "del(rmi_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4064b65-3c45-4c42-a659-58861fbea62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols_by_index(df, index):\n",
    "    column_numbers = [x-1 for x in range(df.shape[1],0,-1)]  # reversed list of columns' integer indices\n",
    "    if type(index)==list:\n",
    "        index.sort()\n",
    "    else:\n",
    "        index = [ index ]\n",
    "    for i in index:\n",
    "        # removing small-to-large index values from large-to-small list means we take from the right, preserving order from zero origin\n",
    "        column_numbers.remove(i)\n",
    "    column_numbers.sort()\n",
    "    return df.iloc[:, column_numbers] # return remaining columns\n",
    "\n",
    "def generate_overview_meta(dd, release_date):\n",
    "    global overview_dd\n",
    "    print('Generating Overview...')\n",
    "    title = dd.loc[0, 'Unnamed: 1']\n",
    "    general_overview = dd.loc[1, 'Unnamed: 2']\n",
    "    scope = dd.loc[2, 'Unnamed: 2']\n",
    "    limitations_to_scope = dd.loc[3, 'Unnamed: 2']\n",
    "    # Drop non-table data captured above\n",
    "    dd = dd.drop(list(range(0,5)))\n",
    "    dd.set_axis(['Name', 'Description'], axis=1,inplace=True)\n",
    "    meta_content = {'title':title, 'description':general_overview, 'version':f'Released {release_date}', 'uri':'https://utilitytransitionhub.rmi.org/data-download/',\n",
    "                    'copyright':'© 2021 RMI', 'license':'Creative Commons Attribution-Noncommercial 4.0 International Public License (CC BY-NC)',\n",
    "                    'contact':'utilitytransitionhub@rmi.org', 'abstract':'\\n'.join([scope, limitations_to_scope]), 'name':'rmi_utility_transition_hub' }\n",
    "    overview_dd = dd\n",
    "    return meta_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c5e90ac-ee20-4450-8fd3-b1441e95acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "units_dict = {\n",
    "    '$': 'USD',\n",
    "    'number': '',\n",
    "}\n",
    "\n",
    "def generate_generic_meta(sheet, dd):\n",
    "    global overview_dd\n",
    "    \n",
    "    description = overview_dd.loc[overview_dd['Name']==sheet, 'Description'].to_string(index=False)\n",
    "    meta_content = { 'tname':sheet, 'parent_schema':schemaname, 'description':description,\n",
    "                     dd.iloc[-2,0]: dd.iloc[-1,0]}\n",
    "    dd.columns = list(dd.iloc[0])\n",
    "    dd = dd.drop(0, axis=0).drop(dd.tail(2).index).fillna(value='')\n",
    "    meta_fields = {k:{'description': v} for k, v in list(zip(dd.iloc[:, 0], dd.iloc[:, 1]))}\n",
    "    for field, dim in list(zip(dd.iloc[:, 0], dd.iloc[:, 2])):\n",
    "        if dim=='':\n",
    "            continue\n",
    "        if dim in units_dict:\n",
    "            meta_fields[field]['dimension'] = units_dict[dim]\n",
    "        else:\n",
    "            meta_fields[field]['dimension'] = dim\n",
    "\n",
    "    return meta_fields, meta_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be99b50a-7817-458b-b8c4-415222f9ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_assets_meta(sheet, dd):\n",
    "    global overview_dd\n",
    "    description = overview_dd.loc[overview_dd['Name']==sheet, 'Description'].to_string(index=False)\n",
    "    meta_content = { 'tname':sheet, 'parent_schema':schemaname, 'description':description,\n",
    "                     dd.iloc[-2,0]: dd.iloc[-1,0]}\n",
    "    dd.columns = list(dd.iloc[0])\n",
    "    dd = dd.drop(0, axis=0).drop(dd.tail(2).index)\n",
    "    \n",
    "    ### ??? What should we do with enumerations of asset and sub_asset types?\n",
    "    \n",
    "    # Drop columns that exist only to hold enumeration values\n",
    "    dd = drop_cols_by_index(dd, [1,2])\n",
    "    # Asset & sub_asset are actually two fields\n",
    "    fixup_index = dd[dd['Data field']=='asset & sub_asset'].index\n",
    "    dd.loc[fixup_index, 'Data field'] = 'asset'\n",
    "    dd.loc[fixup_index, 'Definition'] = \"RMI's categorization of assets based on grouping of [steam,nuclear,hydro,renewables,other_fossil,transmission,distribution,other]\"\n",
    "    dd.loc[fixup_index+1, 'Data field'] = 'sub_asset'\n",
    "    dd.loc[fixup_index+1, 'Definition'] = \"RMI's categorization of sub_assets when asset=other based on grouping of [AROs,construction_work_in_progress,distribution_arc,electric_plant_held_for_future_use,electric_plant_leased_to_others,experimental_plant,general_plant,general_plant_arc,hydro_arc,intangible_plant,net_ADIT,net_regulatory_assets,net_working_capital,nuclear_arc,other_deferred_debits_and_credits,other_electric_plant,other_fossil_arc,other_noncurrent_liabilities,regional_transmission_and_market_operation,renewables_arc,steam_arc,transmission_arc]\"\n",
    "    dd = dd.dropna(subset=['Data field']).fillna(value='')\n",
    "    \n",
    "    meta_fields = {k:{'description': v} for k, v in list(zip(dd.iloc[:, 0], dd.iloc[:, 1]))}\n",
    "    for field, dim in list(zip(dd.iloc[:, 0], dd.iloc[:, 2])):\n",
    "        if dim=='':\n",
    "            continue\n",
    "        if dim in units_dict:\n",
    "            meta_fields[field]['dimension'] = units_dict[dim]\n",
    "        else:\n",
    "            meta_fields[field]['dimension'] = dim\n",
    "    return meta_fields, meta_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93df34a5-56e0-4a0e-81fc-46219b6adca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_emissions_meta(sheet, dd):\n",
    "    global overview_dd\n",
    "    global operations_emissions_fields, operations_emissions_content\n",
    "    \n",
    "    description = overview_dd.loc[overview_dd['Name']==sheet, 'Description'].to_string(index=False)\n",
    "    meta_content = { 'tname':sheet, 'parent_schema':schemaname, 'description':description,\n",
    "                     dd.iloc[-2,0]: dd.iloc[-1,0]}\n",
    "    dd.columns = list(dd.iloc[0])\n",
    "    dd = dd.drop(0, axis=0).drop(dd.tail(2).index)\n",
    "    \n",
    "    ### ??? What should we do with code enumerations?\n",
    "    \n",
    "    # Drop columns that exist only to hold enumeration values\n",
    "    dd = drop_cols_by_index(dd, 1)\n",
    "    # Strip out enumerations of codes\n",
    "    dd = dd.dropna(subset=['Data field']).fillna(value='')\n",
    "    meta_fields = {k:{'description': v} for k, v in list(zip(dd.iloc[:, 0], dd.iloc[:, 1]))}\n",
    "    \n",
    "    for field, dim in list(zip(dd.iloc[:, 0], dd.iloc[:, 2])):\n",
    "        if dim=='':\n",
    "            continue\n",
    "        if dim in units_dict:\n",
    "            meta_fields[field]['dimension'] = units_dict[dim]\n",
    "        else:\n",
    "            meta_fields[field]['dimension'] = dim\n",
    "    operations_emissions_fields = meta_fields\n",
    "    operations_emissions_content = meta_content\n",
    "    return meta_fields, meta_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fd9e6dc-5f33-4ce4-9577-885a96d3849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bills_meta(sheet, dd):\n",
    "    global overview_dd\n",
    "    description = overview_dd.loc[overview_dd['Name']==sheet, 'Description'].to_string(index=False)\n",
    "    meta_content = { 'tname':sheet, 'parent_schema':schemaname, 'description':description,\n",
    "                     dd.iloc[-2,0]: dd.iloc[-1,0]}\n",
    "    dd.columns = list(dd.iloc[0])\n",
    "    # Temporary fix for bad November 2020 data\n",
    "    if sheet=='revenue_by_tech':\n",
    "        dd = dd.rename(columns={' revenue_total ':'revenue_total', ' revenue_residential ':'revenue_residential'})\n",
    "    dd = dd.drop(0, axis=0).drop(dd.tail(2).index)\n",
    "    \n",
    "    ### ??? What should we do with code enumerations?\n",
    "    \n",
    "    # Drop columns that exist only to hold enumeration values\n",
    "    dd = drop_cols_by_index(dd, 1)\n",
    "    # Strip out enumerations of codes\n",
    "    dd = dd.dropna(subset=['Data field']).fillna(value='')\n",
    "    meta_fields = {k:{'description': v} for k, v in list(zip(dd.iloc[:, 0], dd.iloc[:, 1]))}\n",
    "    for field, dim in list(zip(dd.iloc[:, 0], dd.iloc[:, 2])):\n",
    "        if dim=='':\n",
    "            continue\n",
    "        if dim in units_dict:\n",
    "            meta_fields[field]['dimension'] = units_dict[dim]\n",
    "        else:\n",
    "            meta_fields[field]['dimension'] = dim\n",
    "    return meta_fields, meta_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39579169-ff6a-4985-b41d-b3e841e02e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_other_generation_meta(dd):\n",
    "    global operations_emissions_fields\n",
    "    meta_content = { 'tname':'other_generation', 'parent_schema':schemaname,\n",
    "                     'description': 'EE & DR as well as Purchased Power, all of which count toward `avoided generation`',\n",
    "                     'Additional notes': 'Table derived from operation_emissions_by_field by OS-Climate'}\n",
    "    meta_fields = { ik: operations_emissions_fields[ik] for ik in (operations_emissions_fields.keys() & list(dd.columns))}\n",
    "    return meta_fields, meta_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eec43e-3460-4821-82b7-3837676a0c17",
   "metadata": {},
   "source": [
    "The Data Dictionary is in an XLSX workbook\n",
    "The actual Data lives in seprate CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c44274f-789c-47f7-9f91-9569f7a0ea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_generation_meta_fields = None\n",
    "other_generation_meta_content = None\n",
    "other_generation_df = None\n",
    "\n",
    "def generate_sheet_meta(wb, sheet, release_date):\n",
    "    # For as-yet unexplained reasons, RMI renamed the file assets_earnings_investments.csv\n",
    "    # without updating the name of the sheet in the spreadsheet.  We switch to the intended sheetname here\n",
    "    if sheet == 'assets_earnings':\n",
    "        sheet = 'assets_earnings_investments'\n",
    "    \n",
    "    dd=wb[sheet]\n",
    "    # Remove empty column that appears in all of the spreadsheets\n",
    "    dd = dd.drop('Unnamed: 0', axis=1)\n",
    "    # Given the requested sheet the necessary processing\n",
    "    if sheet=='Overview':\n",
    "        meta_content = generate_overview_meta(dd, release_date)\n",
    "        print('Metadata Overview')\n",
    "        print(meta_content)\n",
    "        return {}, meta_content\n",
    "    if sheet=='data_sources':\n",
    "        return {}, {}\n",
    "    if sheet=='assets_earnings_investments':\n",
    "        return generate_assets_meta(sheet, dd)\n",
    "    if sheet in ['employees', 'expenditure_bills_burden', 'expenditure_bills_burden_detail', 'revenue_by_tech']:\n",
    "        # Both tables have the same essential shape\n",
    "        return generate_bills_meta(sheet, dd)\n",
    "    if sheet in ['operations_emissions_by_fuel', 'operations_emissions_by_tech']:\n",
    "        return generate_emissions_meta(sheet, dd)\n",
    "    if sheet=='other_generation':\n",
    "        return generate_other_generation_meta(dd)\n",
    "    if sheet=='state_utility_policies':\n",
    "        ### df = pd.read_csv(source_bucket.Object(f).get()['Body'],\n",
    "        ###                  dtype={'respondent_id':'int32'},parse_dates=['date_updated'],dayfirst=True)\n",
    "        return generate_generic_meta(sheet, dd)\n",
    "    return generate_generic_meta(sheet, dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5da25147-0270-4b95-a078-dd393b3cef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Overview...\n",
      "Metadata Overview\n",
      "{'title': 'RMI Utility Transition Hub Data Dictionary', 'description': 'The RMI Utility Transition Hub Data Download is a collection of publicly available data, organized and used to calculate key metrics that describe the US utility transition.\\n\\nThis data dictionary describes each data file in detail, including definitions, units, data sources, and methodology.\\n\\nFor downloadable data, visit https://utilitytransitionhub.rmi.org/data-download/.\\nFor interactive data visualizations, visit https://utilitytransitionhub.rmi.org/portal/.\\nFor analyses and insights, visit https://utilitytransitionhub.rmi.org/insights/.', 'version': 'Released January 2022', 'uri': 'https://utilitytransitionhub.rmi.org/data-download/', 'copyright': '© 2021 RMI', 'license': 'Creative Commons Attribution-Noncommercial 4.0 International Public License (CC BY-NC)', 'contact': 'utilitytransitionhub@rmi.org', 'abstract': 'Utilities coverage: all current FERC Form 1 respondents. This includes 403 total companies: \\n         98 vertically integrated utilities\\n         25 restructured utilities\\n       107 wires-only utilities\\n           4 municipal utilities\\n         62 cooperative utilities\\n         39 independent power producers\\n         68 other (or defunct) utilities. \\nGeographical coverage: United States\\nTemporal coverage: 2005-2020 for historical data, and emission target projections to 2050\\nTemporal resolution: annual data\\nThis data set is not comprehensive of all utilities in the United States. If aggregating data to parent companies, values will be the sum of their regulated subsidiaries, not actual total values for the parent company.', 'name': 'rmi_utility_transition_hub'}\n",
      "fname: 'revenue_by_tech.csv'; tablename = 'revenue_by_tech'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 373778 entries, 0 to 373777\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   parent_name          373778 non-null  string        \n",
      " 1   utility_name         373778 non-null  string        \n",
      " 2   respondent_id        373778 non-null  int32         \n",
      " 3   year                 373778 non-null  datetime64[ns]\n",
      " 4   technology           373778 non-null  string        \n",
      " 5   component            373778 non-null  string        \n",
      " 6   detail               373778 non-null  string        \n",
      " 7   revenue_total        373778 non-null  float64       \n",
      " 8   revenue_residential  373265 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int32(1), string(5)\n",
      "memory usage: 24.2 MB\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.revenue_by_tech(\n",
      "    parent_name varchar,\n",
      "    utility_name varchar,\n",
      "    respondent_id integer,\n",
      "    year timestamp(6),\n",
      "    technology varchar,\n",
      "    component varchar,\n",
      "    detail varchar,\n",
      "    revenue_total double,\n",
      "    revenue_residential double\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['year']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "fname: 'expenditure_bills_burden.csv'; tablename = 'expenditure_bills_burden'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 222720 entries, 0 to 222719\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   parent_name            222720 non-null  string        \n",
      " 1   utility_name           222720 non-null  string        \n",
      " 2   respondent_id          222720 non-null  int32         \n",
      " 3   year                   222720 non-null  datetime64[ns]\n",
      " 4   percent_AMI            222720 non-null  string        \n",
      " 5   ownership              222720 non-null  string        \n",
      " 6   electricity_gas_other  222720 non-null  string        \n",
      " 7   technology             222720 non-null  string        \n",
      " 8   expenditure            222720 non-null  float64       \n",
      " 9   bill                   222720 non-null  float64       \n",
      " 10  burden                 222720 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int32(1), string(6)\n",
      "memory usage: 17.8 MB\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.expenditure_bills_burden(\n",
      "    parent_name varchar,\n",
      "    utility_name varchar,\n",
      "    respondent_id integer,\n",
      "    year timestamp(6),\n",
      "    percent_AMI varchar,\n",
      "    ownership varchar,\n",
      "    electricity_gas_other varchar,\n",
      "    technology varchar,\n",
      "    expenditure double,\n",
      "    bill double,\n",
      "    burden double\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['year']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "fname: 'operations_emissions_by_fuel.csv'; tablename = 'operations_emissions_by_fuel'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98267 entries, 0 to 98266\n",
      "Data columns (total 31 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   year                          98267 non-null  datetime64[ns]\n",
      " 1   parent_name                   98267 non-null  string        \n",
      " 2   utility_name                  98267 non-null  string        \n",
      " 3   respondent_id                 98267 non-null  int32         \n",
      " 4   plant_id_eia                  92358 non-null  Int32         \n",
      " 5   plant_name_eia                92358 non-null  string        \n",
      " 6   generator_id                  92358 non-null  string        \n",
      " 7   state                         92278 non-null  string        \n",
      " 8   city                          91743 non-null  string        \n",
      " 9   county                        88786 non-null  string        \n",
      " 10  latitude                      92066 non-null  float64       \n",
      " 11  longitude                     92346 non-null  float64       \n",
      " 12  balancing_authority_code_eia  89507 non-null  string        \n",
      " 13  balancing_authority_name_eia  87788 non-null  string        \n",
      " 14  iso_rto_code                  47882 non-null  string        \n",
      " 15  nerc_region                   100 non-null    string        \n",
      " 16  owned_or_total                98267 non-null  string        \n",
      " 17  status                        98267 non-null  string        \n",
      " 18  operating_month               90066 non-null  Int32         \n",
      " 19  operating_year                90066 non-null  Int32         \n",
      " 20  retirement_month              1860 non-null   Int32         \n",
      " 21  retirement_year               1860 non-null   Int32         \n",
      " 22  technology_EIA                98096 non-null  string        \n",
      " 23  technology_RMI                98096 non-null  string        \n",
      " 24  fuel_type_code                92358 non-null  string        \n",
      " 25  fuel_type_category            92356 non-null  string        \n",
      " 26  generation                    98267 non-null  float64       \n",
      " 27  fuel_consumption              98267 non-null  float64       \n",
      " 28  emissions_co2                 98267 non-null  float64       \n",
      " 29  emissions_nox                 98267 non-null  float64       \n",
      " 30  emissions_sox                 98267 non-null  float64       \n",
      "dtypes: Int32(5), datetime64[ns](1), float64(7), int32(1), string(17)\n",
      "memory usage: 21.5 MB\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.other_generation(\n",
      "    year timestamp(6),\n",
      "    parent_name varchar,\n",
      "    utility_name varchar,\n",
      "    respondent_id integer,\n",
      "    owned_or_total varchar,\n",
      "    status varchar,\n",
      "    technology_EIA varchar,\n",
      "    technology_RMI varchar,\n",
      "    generation double,\n",
      "    fuel_consumption double,\n",
      "    emissions_co2 double,\n",
      "    emissions_nox double,\n",
      "    emissions_sox double\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['year']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.operations_emissions_by_fuel(\n",
      "    year timestamp(6),\n",
      "    parent_name varchar,\n",
      "    utility_name varchar,\n",
      "    respondent_id integer,\n",
      "    plant_id_eia integer,\n",
      "    plant_name_eia varchar,\n",
      "    generator_id varchar,\n",
      "    state varchar,\n",
      "    city varchar,\n",
      "    county varchar,\n",
      "    latitude double,\n",
      "    longitude double,\n",
      "    balancing_authority_code_eia varchar,\n",
      "    balancing_authority_name_eia varchar,\n",
      "    iso_rto_code varchar,\n",
      "    nerc_region varchar,\n",
      "    owned_or_total varchar,\n",
      "    status varchar,\n",
      "    operating_month integer,\n",
      "    operating_year integer,\n",
      "    retirement_month integer,\n",
      "    retirement_year integer,\n",
      "    technology_EIA varchar,\n",
      "    technology_RMI varchar,\n",
      "    fuel_type_code varchar,\n",
      "    fuel_type_category varchar,\n",
      "    generation double,\n",
      "    fuel_consumption double,\n",
      "    emissions_co2 double,\n",
      "    emissions_nox double,\n",
      "    emissions_sox double\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['year']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "fname: 'operations_emissions_by_tech.csv'; tablename = 'operations_emissions_by_tech'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77667 entries, 0 to 77666\n",
      "Data columns (total 33 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   year                          77667 non-null  datetime64[ns]\n",
      " 1   parent_name                   77667 non-null  string        \n",
      " 2   utility_name                  77667 non-null  string        \n",
      " 3   respondent_id                 77667 non-null  int32         \n",
      " 4   plant_id_eia                  71758 non-null  Int32         \n",
      " 5   plant_name_eia                71758 non-null  string        \n",
      " 6   generator_id                  71758 non-null  string        \n",
      " 7   state                         71678 non-null  string        \n",
      " 8   city                          71209 non-null  string        \n",
      " 9   county                        68528 non-null  string        \n",
      " 10  latitude                      71534 non-null  float64       \n",
      " 11  longitude                     71750 non-null  float64       \n",
      " 12  balancing_authority_code_eia  69188 non-null  string        \n",
      " 13  balancing_authority_name_eia  67943 non-null  string        \n",
      " 14  iso_rto_code                  38277 non-null  string        \n",
      " 15  nerc_region                   76 non-null     string        \n",
      " 16  owned_or_total                77667 non-null  string        \n",
      " 17  status                        77667 non-null  string        \n",
      " 18  operating_month               69739 non-null  float64       \n",
      " 19  operating_year                69739 non-null  float64       \n",
      " 20  retirement_month              1248 non-null   float64       \n",
      " 21  retirement_year               1248 non-null   float64       \n",
      " 22  technology_EIA                77600 non-null  string        \n",
      " 23  technology_RMI                77600 non-null  string        \n",
      " 24  capacity                      73777 non-null  float64       \n",
      " 25  year_end_capacity             71274 non-null  float64       \n",
      " 26  generation                    77667 non-null  float64       \n",
      " 27  potential_generation          69739 non-null  float64       \n",
      " 28  capacity_factor               69739 non-null  float64       \n",
      " 29  fuel_consumption              77667 non-null  float64       \n",
      " 30  emissions_co2                 77667 non-null  float64       \n",
      " 31  emissions_nox                 77667 non-null  float64       \n",
      " 32  emissions_sox                 77667 non-null  float64       \n",
      "dtypes: Int32(1), datetime64[ns](1), float64(15), int32(1), string(15)\n",
      "memory usage: 19.0 MB\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.operations_emissions_by_tech(\n",
      "    year timestamp(6),\n",
      "    parent_name varchar,\n",
      "    utility_name varchar,\n",
      "    respondent_id integer,\n",
      "    plant_id_eia integer,\n",
      "    plant_name_eia varchar,\n",
      "    generator_id varchar,\n",
      "    state varchar,\n",
      "    city varchar,\n",
      "    county varchar,\n",
      "    latitude double,\n",
      "    longitude double,\n",
      "    balancing_authority_code_eia varchar,\n",
      "    balancing_authority_name_eia varchar,\n",
      "    iso_rto_code varchar,\n",
      "    nerc_region varchar,\n",
      "    owned_or_total varchar,\n",
      "    status varchar,\n",
      "    operating_month double,\n",
      "    operating_year double,\n",
      "    retirement_month double,\n",
      "    retirement_year double,\n",
      "    technology_EIA varchar,\n",
      "    technology_RMI varchar,\n",
      "    capacity double,\n",
      "    year_end_capacity double,\n",
      "    generation double,\n",
      "    potential_generation double,\n",
      "    capacity_factor double,\n",
      "    fuel_consumption double,\n",
      "    emissions_co2 double,\n",
      "    emissions_nox double,\n",
      "    emissions_sox double\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['year']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "fname: 'assets_earnings_investments.csv'; tablename = 'assets_earnings_investments'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52136 entries, 0 to 52135\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   parent_name       52136 non-null  string        \n",
      " 1   utility_name      52136 non-null  string        \n",
      " 2   respondent_id     52136 non-null  int32         \n",
      " 3   year              52136 non-null  datetime64[ns]\n",
      " 4   asset             52136 non-null  string        \n",
      " 5   sub_asset         52136 non-null  string        \n",
      " 6   asset_value       51627 non-null  float64       \n",
      " 7   earnings_value    50565 non-null  float64       \n",
      " 8   investment_value  15371 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int32(1), string(4)\n",
      "memory usage: 3.4 MB\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.assets_earnings_investments(\n",
      "    parent_name varchar,\n",
      "    utility_name varchar,\n",
      "    respondent_id integer,\n",
      "    year timestamp(6),\n",
      "    asset varchar,\n",
      "    sub_asset varchar,\n",
      "    asset_value double,\n",
      "    earnings_value double,\n",
      "    investment_value double\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['year']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "fname: 'net_plant_balance.csv'; tablename = 'net_plant_balance'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17549 entries, 0 to 17548\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   parent_name        17549 non-null  string        \n",
      " 1   utility_name       17549 non-null  string        \n",
      " 2   respondent_id      17549 non-null  int32         \n",
      " 3   year               17549 non-null  datetime64[ns]\n",
      " 4   FERC_class         17549 non-null  string        \n",
      " 5   original_cost      15871 non-null  float64       \n",
      " 6   accum_depr         12946 non-null  float64       \n",
      " 7   net_plant_balance  15871 non-null  float64       \n",
      " 8   ARC                6011 non-null   float64       \n",
      " 9   ARC_accum_depr     7468 non-null   float64       \n",
      " 10  net_ARC            6011 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int32(1), string(3)\n",
      "memory usage: 1.4 MB\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.net_plant_balance(\n",
      "    parent_name varchar,\n",
      "    utility_name varchar,\n",
      "    respondent_id integer,\n",
      "    year timestamp(6),\n",
      "    FERC_class varchar,\n",
      "    original_cost double,\n",
      "    accum_depr double,\n",
      "    net_plant_balance double,\n",
      "    ARC double,\n",
      "    ARC_accum_depr double,\n",
      "    net_ARC double\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['year']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "fname: 'housing_units_income.csv'; tablename = 'housing_units_income'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18560 entries, 0 to 18559\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   parent_name    18560 non-null  string        \n",
      " 1   utility_name   18560 non-null  string        \n",
      " 2   respondent_id  18560 non-null  int32         \n",
      " 3   year           18560 non-null  datetime64[ns]\n",
      " 4   percent_AMI    18560 non-null  string        \n",
      " 5   ownership      18560 non-null  string        \n",
      " 6   housing_units  18560 non-null  float64       \n",
      " 7   income         18560 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int32(1), string(4)\n",
      "memory usage: 1.1 MB\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.housing_units_income(\n",
      "    parent_name varchar,\n",
      "    utility_name varchar,\n",
      "    respondent_id integer,\n",
      "    year timestamp(6),\n",
      "    percent_AMI varchar,\n",
      "    ownership varchar,\n",
      "    housing_units double,\n",
      "    income double\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['year']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "fname: 'customers_sales.csv'; tablename = 'customers_sales'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14104 entries, 0 to 14103\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   parent_name        14104 non-null  string        \n",
      " 1   utility_name       14104 non-null  string        \n",
      " 2   respondent_id      14104 non-null  int32         \n",
      " 3   year               14104 non-null  datetime64[ns]\n",
      " 4   customer_type      14104 non-null  string        \n",
      " 5   customer_type_rmi  14104 non-null  string        \n",
      " 6   customers          11833 non-null  Int32         \n",
      " 7   sales              12673 non-null  float64       \n",
      " 8   revenues           14086 non-null  float64       \n",
      "dtypes: Int32(1), datetime64[ns](1), float64(2), int32(1), string(4)\n",
      "memory usage: 895.4 KB\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.customers_sales(\n",
      "    parent_name varchar,\n",
      "    utility_name varchar,\n",
      "    respondent_id integer,\n",
      "    year timestamp(6),\n",
      "    customer_type varchar,\n",
      "    customer_type_rmi varchar,\n",
      "    customers integer,\n",
      "    sales double,\n",
      "    revenues double\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['year']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "fname: 'debt_equity_returns.csv'; tablename = 'debt_equity_returns'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3356 entries, 0 to 3355\n",
      "Data columns (total 27 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   parent_name                3356 non-null   string        \n",
      " 1   utility_name               3356 non-null   string        \n",
      " 2   respondent_id              3356 non-null   int32         \n",
      " 3   year                       3356 non-null   datetime64[ns]\n",
      " 4   rate_base_actual           3354 non-null   float64       \n",
      " 5   equity_actual              3305 non-null   float64       \n",
      " 6   debt_actual                2852 non-null   float64       \n",
      " 7   equity_ratio_actual        2813 non-null   float64       \n",
      " 8   returns_actual             3335 non-null   float64       \n",
      " 9   earnings_actual            3354 non-null   float64       \n",
      " 10  interest_actual            2682 non-null   float64       \n",
      " 11  fed_tax_expense_actual     2943 non-null   float64       \n",
      " 12  pre_tax_net_income_actual  3354 non-null   float64       \n",
      " 13  ROR_actual                 3335 non-null   float64       \n",
      " 14  ROE_actual                 2813 non-null   float64       \n",
      " 15  interest_rate_actual       2654 non-null   float64       \n",
      " 16  equity_ratio               3226 non-null   float64       \n",
      " 17  ROR                        3219 non-null   float64       \n",
      " 18  ROE                        3355 non-null   float64       \n",
      " 19  interest_rate              3354 non-null   float64       \n",
      " 20  effective_fed_tax_rate     2943 non-null   float64       \n",
      " 21  equity_authorized          3226 non-null   float64       \n",
      " 22  debt_authorized            3226 non-null   float64       \n",
      " 23  returns_authorized         3219 non-null   float64       \n",
      " 24  earnings_authorized        3226 non-null   float64       \n",
      " 25  interest_authorized        3219 non-null   float64       \n",
      " 26  interest_rate_authorized   3111 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(23), int32(1), string(2)\n",
      "memory usage: 694.9 KB\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.debt_equity_returns(\n",
      "    parent_name varchar,\n",
      "    utility_name varchar,\n",
      "    respondent_id integer,\n",
      "    year timestamp(6),\n",
      "    rate_base_actual double,\n",
      "    equity_actual double,\n",
      "    debt_actual double,\n",
      "    equity_ratio_actual double,\n",
      "    returns_actual double,\n",
      "    earnings_actual double,\n",
      "    interest_actual double,\n",
      "    fed_tax_expense_actual double,\n",
      "    pre_tax_net_income_actual double,\n",
      "    ROR_actual double,\n",
      "    ROE_actual double,\n",
      "    interest_rate_actual double,\n",
      "    equity_ratio double,\n",
      "    ROR double,\n",
      "    ROE double,\n",
      "    interest_rate double,\n",
      "    effective_fed_tax_rate double,\n",
      "    equity_authorized double,\n",
      "    debt_authorized double,\n",
      "    returns_authorized double,\n",
      "    earnings_authorized double,\n",
      "    interest_authorized double,\n",
      "    interest_rate_authorized double\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['year']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "fname: 'emissions_targets.csv'; tablename = 'emissions_targets'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10061 entries, 0 to 10060\n",
      "Data columns (total 15 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   parent_name                     9952 non-null   string        \n",
      " 1   utility_name                    9994 non-null   string        \n",
      " 2   respondent_id                   9945 non-null   Int32         \n",
      " 3   year                            10061 non-null  datetime64[ns]\n",
      " 4   CO2_historical                  3581 non-null   float64       \n",
      " 5   CO2_target                      315 non-null    float64       \n",
      " 6   CO2_target_all_years            3938 non-null   float64       \n",
      " 7   CO2_1point5C                    9282 non-null   float64       \n",
      " 8   generation_historical           3581 non-null   float64       \n",
      " 9   generation_projected            5642 non-null   float64       \n",
      " 10  generation_1point5C             9282 non-null   float64       \n",
      " 11  CO2_intensity_historical        3255 non-null   float64       \n",
      " 12  CO2_intensity_target            143 non-null    float64       \n",
      " 13  CO2_intensity_target_all_years  2852 non-null   float64       \n",
      " 14  CO2_intensity_1point5C          8313 non-null   float64       \n",
      "dtypes: Int32(1), datetime64[ns](1), float64(11), string(2)\n",
      "memory usage: 1.1 MB\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.emissions_targets(\n",
      "    parent_name varchar,\n",
      "    utility_name varchar,\n",
      "    respondent_id integer,\n",
      "    year timestamp(6),\n",
      "    CO2_historical double,\n",
      "    CO2_target double,\n",
      "    CO2_target_all_years double,\n",
      "    CO2_1point5C double,\n",
      "    generation_historical double,\n",
      "    generation_projected double,\n",
      "    generation_1point5C double,\n",
      "    CO2_intensity_historical double,\n",
      "    CO2_intensity_target double,\n",
      "    CO2_intensity_target_all_years double,\n",
      "    CO2_intensity_1point5C double\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['year']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "fname: 'utility_state_map.csv'; tablename = 'utility_state_map'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5252 entries, 0 to 5251\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   parent_name                 5252 non-null   string \n",
      " 1   utility_name                5252 non-null   string \n",
      " 2   respondent_id               5252 non-null   int32  \n",
      " 3   year                        5252 non-null   int64  \n",
      " 4   state_abbr                  5252 non-null   string \n",
      " 5   state                       5252 non-null   string \n",
      " 6   capacity_owned_in_state     3945 non-null   float64\n",
      " 7   capacity_operated_in_state  3335 non-null   float64\n",
      " 8   mwh_sales_in_state          3263 non-null   float64\n",
      "dtypes: float64(3), int32(1), int64(1), string(4)\n",
      "memory usage: 348.9 KB\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.utility_state_map(\n",
      "    parent_name varchar,\n",
      "    utility_name varchar,\n",
      "    respondent_id integer,\n",
      "    year bigint,\n",
      "    state_abbr varchar,\n",
      "    state varchar,\n",
      "    capacity_owned_in_state double,\n",
      "    capacity_operated_in_state double,\n",
      "    mwh_sales_in_state double\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['year']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "fname: 'employees.csv'; tablename = 'employees'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3399 entries, 0 to 3398\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   parent_name    3399 non-null   string        \n",
      " 1   utility_name   3399 non-null   string        \n",
      " 2   respondent_id  3399 non-null   int32         \n",
      " 3   year           3399 non-null   datetime64[ns]\n",
      " 4   technology     3399 non-null   string        \n",
      " 5   employees      3399 non-null   int32         \n",
      "dtypes: datetime64[ns](1), int32(2), string(3)\n",
      "memory usage: 132.9 KB\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.employees(\n",
      "    parent_name varchar,\n",
      "    utility_name varchar,\n",
      "    respondent_id integer,\n",
      "    year timestamp(6),\n",
      "    technology varchar,\n",
      "    employees integer\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['year']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "fname: 'utility_information.csv'; tablename = 'utility_information'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 403 entries, 0 to 402\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   parent_name               402 non-null    string \n",
      " 1   parent_lei                320 non-null    string \n",
      " 2   parent_ticker             264 non-null    string \n",
      " 3   parent_isin               271 non-null    string \n",
      " 4   utility_name              402 non-null    string \n",
      " 5   respondent_id             403 non-null    int32  \n",
      " 6   utility_id_eia            220 non-null    Int32  \n",
      " 7   utility_lei               169 non-null    string \n",
      " 8   entity_type_eia           218 non-null    string \n",
      " 9   utility_type_rmi          403 non-null    string \n",
      " 10  first_report_year         362 non-null    float64\n",
      " 11  last_report_year          362 non-null    float64\n",
      " 12  duplicate_utility_id_eia  4 non-null      boolean\n",
      "dtypes: Int32(1), boolean(1), float64(2), int32(1), string(8)\n",
      "memory usage: 35.9 KB\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.utility_information(\n",
      "    parent_name varchar,\n",
      "    parent_lei varchar,\n",
      "    parent_ticker varchar,\n",
      "    parent_isin varchar,\n",
      "    utility_name varchar,\n",
      "    respondent_id integer,\n",
      "    utility_id_eia integer,\n",
      "    utility_lei varchar,\n",
      "    entity_type_eia varchar,\n",
      "    utility_type_rmi varchar,\n",
      "    first_report_year double,\n",
      "    last_report_year double,\n",
      "    duplicate_utility_id_eia boolean\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['first_report_year']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "fname: 'state_targets.csv'; tablename = 'state_targets'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   state                 250 non-null    string        \n",
      " 1   year                  110 non-null    datetime64[ns]\n",
      " 2   year_type             250 non-null    string        \n",
      " 3   legal_standard        250 non-null    string        \n",
      " 4   enforcement_standard  250 non-null    string        \n",
      " 5   target_type           250 non-null    string        \n",
      " 6   target_value          126 non-null    string        \n",
      "dtypes: datetime64[ns](1), string(6)\n",
      "memory usage: 13.8 KB\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.state_targets(\n",
      "    state varchar,\n",
      "    year timestamp(6),\n",
      "    year_type varchar,\n",
      "    legal_standard varchar,\n",
      "    enforcement_standard varchar,\n",
      "    target_type varchar,\n",
      "    target_value varchar\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['year']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "fname: 'state_utility_policies.csv'; tablename = 'state_utility_policies'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 191 entries, 0 to 190\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   state                       191 non-null    string        \n",
      " 1   utility_name                191 non-null    string        \n",
      " 2   respondent_id               191 non-null    int32         \n",
      " 3   securitization_policy       191 non-null    string        \n",
      " 4   market_indexing_policy      191 non-null    string        \n",
      " 5   revenue_decoupling          191 non-null    string        \n",
      " 6   governor_party              191 non-null    string        \n",
      " 7   legislation_majority_party  191 non-null    string        \n",
      " 8   date_updated                191 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int32(1), string(7)\n",
      "memory usage: 12.8 KB\n",
      "\n",
      "create table if not exists osc_datacommons_dev.sandbox.state_utility_policies(\n",
      "    state varchar,\n",
      "    utility_name varchar,\n",
      "    respondent_id integer,\n",
      "    securitization_policy varchar,\n",
      "    market_indexing_policy varchar,\n",
      "    revenue_decoupling varchar,\n",
      "    governor_party varchar,\n",
      "    legislation_majority_party varchar,\n",
      "    date_updated timestamp(6)\n",
      ") with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['state']\n",
      ")\n",
      "\n",
      "[(True,)]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "import datetime\n",
    "\n",
    "rmi_ingest_schemas = { # 'rmi_20210929': ('September 2021', rmi_20210929_xls, rmi_20210929_zip),\n",
    "                       # 'rmi_20211120': ('November 2021', rmi_20211120_xls, rmi_20211120_zip),\n",
    "                       'sandbox': ('January 2022', rmi_20220119_xls, rmi_20220119_zip),}\n",
    "\n",
    "def first_valid_col_value(df, col):\n",
    "    return df.loc[df[col].first_valid_index(), col]\n",
    "\n",
    "# There is no datafile behind the data dictionary.  Run this to prime overview_dd, which all other metadata-finding depends upon\n",
    "for schemaname, (release_date, workbook, zipfile) in rmi_ingest_schemas.items():\n",
    "    # The dataframe for Non-Null data\n",
    "    df_nn = None\n",
    "    overview_dd = None\n",
    "    operations_emissions_content = None\n",
    "    operations_emissions_fields = None\n",
    "\n",
    "    overview_meta_fields, overview_meta_content = generate_sheet_meta(workbook, 'Overview', release_date)\n",
    "\n",
    "    for zipinfo in zipfile.infolist():\n",
    "        fname = zipinfo.filename\n",
    "        ftimestamp = datetime.datetime(*zipinfo.date_time)\n",
    "        if fname[-4:] != '.csv':\n",
    "            continue\n",
    "        if fname.startswith('__MACOSX/._'):\n",
    "            continue\n",
    "\n",
    "        tablename = fname.split('/')[-1].split('.')[0]\n",
    "        # For as-yet unexplained reasons, RMI renamed the file assets_earnings_investments.csv\n",
    "        # without updating the name of the sheet in the spreadsheet.  We switch to the intended name here\n",
    "        if tablename == 'assets_earnings':\n",
    "            tablename = 'assets_earnings_investments'\n",
    "        if tablename == 'expenditure_bills_burden_detail':\n",
    "            continue\n",
    "\n",
    "        print(f\"fname: '{fname}'; tablename = '{tablename}'\")\n",
    "        with zipfile.open(fname) as zf:\n",
    "            if tablename=='state_utility_policies':\n",
    "                df = pd.read_csv(zf, dtype={'respondent_id':'int32'},parse_dates=['date_updated'],dayfirst=True, engine='c')\n",
    "            elif tablename.startswith('utility'):\n",
    "                df = pd.read_csv(zf, dtype=dtype_dict[tablename], engine='c')\n",
    "                if tablename=='utility_information' and schemaname <= 'rmi_20211120':\n",
    "                    # Correct information for 'American Transmission Co LLC', which is owned by 'WEC Energy Group'\n",
    "                    df.loc[df.respondent_id==275, ['parent_name', 'parent_ticker', 'parent_ISIN', 'parent_LEI']] = df.loc[df.respondent_id==519, ['parent_name', 'parent_ticker', 'parent_ISIN', 'parent_LEI']].values\n",
    "                    df = df.rename(columns={'parent_ISIN':'parent_isin', 'parent_LEI':'parent_lei'})\n",
    "                if tablename=='utility_information':\n",
    "                    # Correct several LEI errors and omissions\n",
    "                    df.loc[df.parent_name=='American Electric Power Co., Inc.', 'parent_lei'] = '1B4S6S7G0TW5EE83BO58'\n",
    "                    df.loc[df.parent_name=='American States Water Co.', 'parent_isin'] = first_valid_col_value(df[df.parent_name=='American States Water Co.'], 'parent_isin')\n",
    "                    df.loc[df.parent_name=='American States Water Co.', 'parent_lei'] = '529900L26LIS2V8PWM23'\n",
    "                    df.loc[df.parent_name=='Berkshire Hathaway, Inc.', 'parent_lei'] = '5493000C01ZX7D35SD85'\n",
    "                    df.loc[df.parent_name=='Citizens Energy Corp.', 'parent_lei'] = '5493008ORX814MK1WM19'\n",
    "                    df.loc[df.parent_name=='FirstEnergy Corp.', 'parent_lei'] = '549300SVYJS666PQJH88'\n",
    "                    df.loc[df.parent_name=='LS Power', 'parent_lei'] = '549300Z88AAE0R1YHI77'\n",
    "                    df.loc[df.parent_name=='NextEra Energy, Inc.', 'parent_lei'] = 'UMI46YPGBLUE4VGNNT48'\n",
    "                    df.loc[df.parent_name=='PG&E Corp.', 'parent_lei'] = '8YQ2GSDWYZXO2EDN3511'\n",
    "                    df.loc[df.parent_name=='Sempra', 'parent_isin'] = first_valid_col_value(df[df.parent_name=='Sempra'], 'parent_isin')\n",
    "                    df.loc[df.parent_name=='Sempra', 'parent_lei'] = 'PBBKGKLRK5S5C0Y4T545'\n",
    "                    df.loc[df.parent_name=='Unitil Corp.', 'parent_lei'] = '549300EYGHO5EZE7RL80'\n",
    "                    df.loc[df.parent_name=='Verso Corp.', 'parent_lei'] = '549300FODXCTQ8DGT594'\n",
    "                    df.loc[df.parent_name=='Verso Corp.', 'parent_isin'] = 'US92531L2079'\n",
    "            elif tablename=='state_targets':\n",
    "                df = pd.read_csv(zf, dtype=dtype_dict[tablename], engine='c')\n",
    "                df.year.fillna('-1', inplace=True)\n",
    "                df.year = df.year.astype('string')\n",
    "                df.loc[df.year.isin(['Annual','2005/1990']), 'year'] = '-1'\n",
    "                df.year = pd.to_datetime(df.year.map(lambda x: x.split('.')[0]).astype('int32'), format='%Y', errors='coerce')\n",
    "            else:\n",
    "                df = pd.read_csv(zf, dtype=dtype_dict[tablename], thousands=',', engine='c')\n",
    "                if 'year' in df.columns:\n",
    "                    df.year.fillna('-1', inplace=True)\n",
    "                    df.year = df.year.astype('string')\n",
    "                    df.year = pd.to_datetime(df.year.map(lambda x: x.split('.')[0]).astype('int32'), format='%Y', errors='coerce')\n",
    "                if tablename=='revenue_by_tech':\n",
    "                    # The 2020 numbers come with extra spaces, comma separators, and sometimes parentheses instead of minus signs.\n",
    "                    def cleanup_2020_numbers(s):\n",
    "                        if type(s)==float:\n",
    "                            return s\n",
    "                        if s is None or s=='' or pd.isnull(s):\n",
    "                            return 'nan'\n",
    "                        s = s.strip().replace(',','')\n",
    "                        if s[0]=='(':\n",
    "                            s = s[1:-1]\n",
    "                        elif s=='#NAME?':\n",
    "                            s = 'nan'\n",
    "                        return s\n",
    "                    df.rename(columns={' revenue_total ':'revenue_total', ' revenue_residential ':'revenue_residential'}, inplace=True)\n",
    "                    df.revenue_total = df.revenue_total.map(cleanup_2020_numbers).astype('float64')\n",
    "                    df.revenue_residential = df.revenue_residential.map(cleanup_2020_numbers).astype('float64')\n",
    "            df = df.convert_dtypes(infer_objects=False, convert_string=True, convert_integer=False, convert_boolean=False, convert_floating=False)\n",
    "            df.info(verbose=True)\n",
    "\n",
    "        if tablename in dropna_dict:\n",
    "            df.dropna(subset=list(dropna_dict[tablename].keys()), inplace=True)\n",
    "        if tablename in fillna_dict:\n",
    "            df.fillna(value=fillna_dict[tablename], inplace=True)\n",
    "\n",
    "        custom_meta_fields, custom_meta_content = generate_sheet_meta(workbook, tablename, release_date)\n",
    "        if tablename in ['operations_emissions_by_fuel', 'operations_emissions_by_tech']:\n",
    "            # Both tables duplicate the 'Purchased Power' and 'EE & DR' data.\n",
    "            # We only need one copy, which we create as 'other_generation'\n",
    "            if df_nn is None:\n",
    "                df_anon = df.loc[df['plant_name_eia'].isna()].copy()\n",
    "                # Drop many NULL columns we don't need\n",
    "                df_anon.dropna(axis=1, how='all', inplace=True)\n",
    "                other_generation_df = df_anon\n",
    "                custom_gen_meta_fields, custom_gen_meta_content = generate_other_generation_meta(df_anon)\n",
    "                \n",
    "                ingest_table = 'other_generation'\n",
    "                columnschema = osc.create_table_schema_pairs(df_anon,\n",
    "                                                             typemap={\"datetime64[ns]\":\"timestamp(6)\"})\n",
    "\n",
    "                tabledef = f\"\"\"\n",
    "create table if not exists {ingest_catalog}.{ingest_schema}.{ingest_table}(\n",
    "{columnschema}\n",
    ") with (\n",
    "    format = 'ORC',\n",
    "    partitioning = array['year']\n",
    ")\n",
    "\"\"\"\n",
    "                print(tabledef)\n",
    "                qres = engine.execute(tabledef)\n",
    "                print(qres.fetchall())\n",
    "                df_anon.to_sql(ingest_table,\n",
    "                               con=engine, schema=ingest_schema, if_exists='append',\n",
    "                               index=False,\n",
    "                               method=osc.TrinoBatchInsert(batch_size = 2000, verbose = False))\n",
    "                df_nn = df.loc[~df['operating_month'].isna()]\n",
    "            df.dropna(subset=['plant_name_eia'], inplace=True)\n",
    "            # For some reason, data before 2010 is sometimes not filled in.\n",
    "            for index, row in df[df['operating_month'].isna()].iterrows():\n",
    "                # df_nn is only computed once, from either 'operations_emissions_by_fuel' or 'operations_emissions_by_tech'\n",
    "                df0 = df_nn.loc[(df_nn['respondent_id']==row['respondent_id']) & (df_nn['generator_id']==row['generator_id']), ['operating_month', 'operating_year']]\n",
    "                if len(df0)==0:\n",
    "                    # In this case we have no prior data to refer to\n",
    "                    continue\n",
    "                om, oy = df0.iloc[0]\n",
    "                df.loc[index, ('operating_month', 'operating_year')] = om, oy\n",
    "            # ICEBERG does not support integers less than 32 bits\n",
    "            # for colname in ['operating_month', 'operating_year', 'retirement_month', 'retirement_year']:\n",
    "            #     df[colname] = pd.to_numeric(df[colname],downcast='integer')\n",
    "            #     pass\n",
    "        elif tablename=='emissions_targets':\n",
    "            # Needed because respondent_id 191 data is duplicated (and 121 is kinda duplicated, too).\n",
    "            df.drop_duplicates(subset=None, keep='first', inplace=True, ignore_index=True)\n",
    "            df.loc[df['CO2_intensity_historical']==np.inf, ['CO2_historical', 'CO2_intensity_historical']] = [0, 0]\n",
    "            df['CO2_intensity_historical'] = df['CO2_intensity_historical'].astype('float64')\n",
    "            \n",
    "            # Fix discrepencies between emissions_targets and the other files that define/reference parent_name\n",
    "            df.loc[df.parent_name=='American States Water', 'parent_name'] = 'American States Water Co.'\n",
    "            df.loc[df.parent_name=='CMS Energy', 'parent_name'] = 'CMS Energy Corp.'\n",
    "            df.loc[df.parent_name=='Emera Inc.', 'parent_name'] = 'Versant Power'\n",
    "            df.loc[df.parent_name=='Fortis, Inc', 'parent_name'] = 'Fortis, Inc.'\n",
    "            df.loc[df.parent_name=='National Grid plc', 'parent_name'] = 'National Grid PLC'\n",
    "            df.loc[df.parent_name=='NorthWestern Corp.', 'parent_name'] = 'Northwestern Corp.'\n",
    "            df.loc[df.parent_name=='OG&E Energy', 'parent_name'] = 'OG&E Energy Corp.'\n",
    "            df.loc[df.parent_name=='PPL', 'parent_name'] = 'PPL Corp.'\n",
    "            df.loc[df.parent_name=='Sempra Energy', 'parent_name'] = 'Sempra'\n",
    "            df.loc[df.parent_name=='Verso', 'parent_name'] = 'Verso Corp.'\n",
    "        # if tablename in tidy_dict:\n",
    "        #     tidy_df = df.melt(id_vars=tidy_dict[tablename][0], value_vars=tidy_dict[tablename][2],\n",
    "        #                       var_name=tidy_dict[tablename][1][0], value_name=tidy_dict[tablename][1][1])\n",
    "        #     tidy_df[tidy_dict[tablename][1][0]] = tidy_df[tidy_dict[tablename][1][0]].apply(lambda x: x.split('_')[0])\n",
    "        #     tidy_df.dropna(subset=[tidy_dict[tablename][1][1]],inplace=True)\n",
    "        \n",
    "        ingest_table = tablename\n",
    "        columnschema = osc.create_table_schema_pairs(df, typemap={\"datetime64[ns]\":\"timestamp(6)\"})\n",
    "\n",
    "        if 'year' in df.columns:\n",
    "            partition = 'year'\n",
    "        elif 'first_report_year' in df.columns:\n",
    "            partition = 'first_report_year'\n",
    "        elif 'state' in df.columns:\n",
    "            partition = 'state'\n",
    "        else:\n",
    "            raise KeyError\n",
    "\n",
    "        tabledef = f\"\"\"\n",
    "create table if not exists {ingest_catalog}.{ingest_schema}.{ingest_table}(\n",
    "{columnschema}\n",
    ") with (\n",
    "    format = 'ORC',\n",
    "    partitioning = array['{partition}']\n",
    ")\n",
    "\"\"\"\n",
    "        print(tabledef)\n",
    "        qres = engine.execute(tabledef)\n",
    "        print(qres.fetchall())\n",
    "        df.to_sql(ingest_table,\n",
    "                  con=engine, schema=ingest_schema, if_exists='append',\n",
    "                  index=False,\n",
    "                  method=osc.TrinoBatchInsert(batch_size = 2000, verbose = False))\n",
    "    zipfile.close()\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096b05a-b171-4cef-8a47-12fb957867b3",
   "metadata": {},
   "source": [
    "Iterate through tablenames until we get to *Additional Information*, storing all the names and descriptions of the tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b07bf75-c64a-4059-936d-4bd2253fa0d9",
   "metadata": {},
   "source": [
    "We've already collected the field names, types, dimensions, etc., of each table into our dataframes.\n",
    "But there's additional metadata we can collect from the data dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fde1a9-b84d-4d16-a89c-38d939ab71a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load metadata following an ingestion process into trino metadata store\n",
    "\n",
    "### The schema is *metastore*, and the table names are *meta_schema*, *meta_table*, *meta_field*"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a250c477-b73a-4c99-b889-d48e7b756df9",
   "metadata": {},
   "source": [
    "metastore = 'metastore'\n",
    "\n",
    "# Create a metadata schema with tables for the three layers of metadata: schema, table, and field.\n",
    "\n",
    "meta_schema = 'meta_schema'\n",
    "meta_table = 'meta_table'\n",
    "meta_field = 'meta_field'\n",
    "\n",
    "# These metadata tables are local to this ingestion process.\n",
    "# We will insert/merge with master metadata tables later\n",
    "\n",
    "metadata_to_df = {\n",
    "    # For each data source there is a single entry in the _schema_table\n",
    "    meta_schema: pd.DataFrame(data=[], columns=[]),\n",
    "    # For each data source there are one or more tables in the _tables_table\n",
    "    meta_table: pd.DataFrame(data=[],\n",
    "                    columns=['tname', 'parent_schema', 'source', 'processing_pipeline']),\n",
    "    # For each table there are one or more fields in the fields_table\n",
    "    meta_field: pd.DataFrame(data=[],\n",
    "                    columns=['fname', 'parent_table', 'type', 'dimension', 'description'])\n",
    "}\n",
    "\n",
    "cur.execute(f'create schema if not exists {metastore}')\n",
    "cur.fetchall()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
